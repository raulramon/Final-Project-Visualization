---
title: "Random Forest"
output: html_notebook
---

```{r}
library(tidyverse)
```


#Random Forest

#Read Data
```{r}
CTG <- read.csv("C:/Users/17875/Downloads/CTG.csv", header = TRUE)
str(CTG)
CTG$NSP <- as.factor(CTG$NSP)
table(CTG$NSP)
```


# Data Partition
```{r}
set.seed(123)
ind <- sample(2, nrow(CTG), replace = TRUE, prob = c(0.7, 0.3))
train <- CTG[ind==1,]
test <- CTG[ind==1,]
```


#Random Forest
```{r}
library(randomForest)
set.seed(222)
rf <- randomForest(NSP~., data = train)
rf
```
 Number of trees: 500 #<-- ntree
No. of variables tried at each split: 4  <--mtry
```{r}
attributes(rf)
```

```{r}
rf$confusion
```

```{r}
rf_frame1 <- rf$confusion
rf_frame1
```

```{r}
rf_dframe1 <- as.data.frame(rf_frame1)
rf_dframe1 <- mutate(rf_dframe1, tab = "rf1")
rf_dframe1
write.csv(rf_dframe1, "rf1_RF.csv")
```


#Prediction and Confusion Matrix --- train data
```{r}
library(caret)
p1 <- predict(rf, train)
head(p1)
head(train$NSP)
```

```{r}
p1cm <- confusionMatrix(p1, train$NSP)
p1cm
```

```{r}
p1rf_dframe <- p1cm$table
p1rf_dframe <- as.data.frame(p1rf_dframe)
p1rf_dframe <- mutate(p1rf_dframe, tab = "p1rf1")
p1rf_dframe
write.csv(p1rf_dframe, "p1rf_RF.csv")
```


#Prediction with test Data
```{r}
p2 <- predict(rf, test)
p2cm <- confusionMatrix(p2, test$NSP)
p2cm
```

```{r}
p2rf_dframe <- p2cm$table
p2rf_dframe <- as.data.frame(p2rf_dframe)
p2rf_dframe <- mutate(p2rf_dframe, tab = "p2rf2")
p2rf_dframe
write.csv(p2rf_dframe, "p2rf_RF.csv")
```

```{r}
rf$
```


#Error Rate of Raondom forest Model
```{r}
plot(rf)
```

#Tune mtry
```{r}
t <- tuneRF(train[,-22], train[,22],
       stepFactor = .5, 
       plot = TRUE,
       ntreeTry = 300,
       trace = TRUE,
       improve = 0.05)
t
```

```{r}
tframe <- as.data.frame(t)
tframe
```

tune_tframe
```{r}
write.csv(tframe, "tframe_randomF.csv")
```


#Ramdon Forest Model
```{r}
set.seed(222)
rf300 <- randomForest(NSP~., data = train,
                   ntree =300,
                   mtry = 8,
                   importance = TRUE,
                   proximity = TRUE)
rf300
```


```{r}
attributes(rf300)
```

```{r}
rf300$confusion
rf_frame2 <- rf300$confusion
rf_frame2
```

```{r}
rf_dframe2 <- as.matrix(rf_frame2)
#rf_dframe2 <- mutate(rf_dframe1, tab = "rf300")
rf_dframe2
#write.csv(rf_dframe2, "rf2_RF.csv")
```



#No. Nodes for the Trees
```{r}
hist(treesize(rf300),
     main = "No. Nodes for the Trees",
     col = "green")
```

#Variable  Importance
```{r}
varImpPlot(rf300,
           sort = T,
           n.var = 10,
           main = "Top 10 Variable  Importance")
importance(rf300)
varUsed(rf300)
```

```{r}
rf300
```



#Partial Defendence Plot
```{r}
partialPlot(rf300, train, ASTV, "3")
```

#Extract single tree
```{r}

theTree <- getTree(rf300, 1, labelVar = TRUE)
theTree
```

```{r}
theTree <- as.data.frame(theTree)
theTree
write.csv(theTree, 'theTree_RF.csv')
```


#Multi-dimensional Scaling Plot of Proximity Matrix
```{r}
MDSplot(rf300, train$NSP)
```
```{r}
plot(theTree)
```


```{r}
total_rf <- rbind(p1rf_dframe,p2rf_dframe)
total_rf
total_rf2 <- rbind(rf_dframe1,rf_dframe2)
total_rf2
```


Neural Network
Deep Learning Neural Network
Random Forest
SVM
AutoML model